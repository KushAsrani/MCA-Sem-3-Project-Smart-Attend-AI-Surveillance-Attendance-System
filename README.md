# Smart-Attend: AI Surveillance Attendance System

Smart-Attend is an AI-powered attendance system built for real-time surveillance and automated attendance logging. This project combines face detection, face recognition, and attendance recording to create a practical solution suitable for classrooms, small offices, and controlled access environments.

Key goals:
- Automatically detect and recognize people from live camera feeds or recorded video.
- Log attendance with timestamps and optional metadata.
- Provide tools for dataset collection, training, evaluation, and demoing the system.

---

## Table of Contents
- [Features](#features)
- [Project Structure](#project-structure)
- [Requirements](#requirements)
- [Installation](#installation)
- [Preparing the Dataset](#preparing-the-dataset)
- [Training a Model](#training-a-model)
- [Running the Real-time Attendance Demo](#running-the-real-time-attendance-demo)
- [Usage Examples](#usage-examples)
- [Output / Attendance Format](#output--attendance-format)
- [Improving Accuracy](#improving-accuracy)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgements & References](#acknowledgements--references)

---

## Features
- Real-time face detection (via OpenCV / Haar cascades or modern detectors).
- Face encoding and recognition pipeline (classical encodings or deep models).
- Attendance logging to CSV (with timestamp and optional confidence/ID).
- Scripts for dataset collection, encoding generation, and model training.
- Simple CLI to run on webcam or video file.

---

## Project Structure (typical)
Note: adapt to actual files in the repo; filenames below are examples used by the README commands.
```plaintext
- data/
  - dataset/               # Per-person folders with face images
  - encodings.pickle       # Serialized face encodings (generated after training)
  - attendance.csv         # Output log generated by the demo
- models/
  - recognition_model.*    # Optional trained model artifacts
- scripts/
  - collect_dataset.py     # Capture faces / build dataset
  - encode_faces.py        # Generate encodings from the dataset
  - train.py               # Train a recognition classifier (optional)
  - recognize.py           # Real-time recognition & attendance logging
- notebooks/               # EDA and training experiments
- requirements.txt
- README.md
```

---

## Requirements
- Python 3.8+
- OpenCV (cv2)
- face_recognition (depends on dlib) OR an alternative face recognition backend
- numpy, pandas, scikit-learn
- (Optional) tensorflow / keras / pytorch â€” if deep-learning based models are used
- USB webcam (for live demo) or a video file

Example (common) packages:
- opencv-python
- face_recognition
- dlib (system-level install may be required)
- numpy
- pandas
- scikit-learn

---

## Installation

1. Clone the repository
   ```bash
   git clone https://github.com/KushAsrani/MCA-Sem-3-Project-Smart-Attend-AI-Surveillance-Attendance-System.git
   cd MCA-Sem-3-Project-Smart-Attend-AI-Surveillance-Attendance-System
   ```

2. Create and activate a virtual environment
   ```bash
   python3 -m venv venv
   venv\Scripts\activate      # Windows
   source venv/bin/activate   # Linux / macOS
   ```

3. Install Python requirements
   ```bash
   pip install -r requirements.txt
   ```
4. Run the development server
   ```bash
   python app.py
   ```

Notes:
- Installing dlib can require system packages and a C++ compiler. On many Linux distributions:
  sudo apt-get install build-essential cmake
  pip install dlib
- If you cannot install dlib, consider replacing face_recognition with a pure TensorFlow / PyTorch model (adjust scripts accordingly).

---

## Preparing the Dataset

Collect a dataset of faces organized by person. A recommended directory layout.

You can use scripts/collect_dataset.py to capture images from a webcam and save them into per-person folders.

Example:
python scripts/collect_dataset.py --output-dir data/dataset/Alice --num-samples 50

---

## Generating Encodings / Training

To prepare for recognition, create encodings from the dataset:

python scripts/encode_faces.py --dataset data/dataset --encodings data/encodings.pickle

This script typically:
- Loads each image in the dataset
- Detects faces
- Computes face encodings
- Serializes encodings and corresponding labels to encodings.pickle

Optionally, train a classifier (e.g., SVM, LogisticRegression) on the encodings:

python scripts/train.py --encodings data/encodings.pickle --model models/recognizer.pickle

The trained classifier can be used by the recognition script for faster/robust predictions.

---

## Running the Real-time Attendance Demo

Run recognition against a webcam or a video file and log attendance:

python scripts/recognize.py --encodings data/encodings.pickle --output data/attendance.csv
# For a video file:
python scripts/recognize.py --encodings data/encodings.pickle --video demo/video1.mp4 --output data/attendance.csv

Typical behavior:
- Opens webcam (or video) window with bounding boxes and labels
- When a recognized person is detected, their presence is logged in attendance.csv with timestamp and confidence
- Repeated detections within a short timeframe can be suppressed to avoid duplicate entries (configurable)

---

## Usage Examples

- Capture dataset samples for a new user:
  python scripts/collect_dataset.py --output-dir data/dataset/David --num-samples 100

- Generate face encodings:
  python scripts/encode_faces.py --dataset data/dataset --encodings data/encodings.pickle

- Train a linear SVM classifier:
  python scripts/train.py --encodings data/encodings.pickle --model models/recognizer.pickle

- Start the attendance system on the webcam:
  python scripts/recognize.py --encodings data/encodings.pickle --model models/recognizer.pickle --output data/attendance.csv

Refer to the script-level help (use --help) to see additional options (confidence thresholds, detection backend, frame-skip, etc.).

---

## Output / Attendance Format

Attendance logs are generally CSV files with columns such as:
- id / name
- timestamp (ISO 8601)
- confidence (optional)
- source (webcam / video filename)
- bounding_box coordinates (optional)

Example:
name,timestamp,confidence,source
Alice,2025-11-29T14:00:12Z,0.96,webcam

---

## Improving Accuracy & Robustness
- Increase dataset size and diversity (lighting, pose, expression).
- Use higher-quality face detectors (MTCNN, RetinaFace, or YOLO-based face detectors).
- Use a modern deep embedding model (ArcFace, FaceNet) for embeddings.
- Fine-tune classifier or use metric-learning approaches.
- Add data augmentation (brightness, occlusion, rotations).
- Normalize frames and use histogram equalization for varying lighting.

---

## Troubleshooting

- Issue: dlib install failures
  - Solution: install system prerequisites (cmake, build essentials) and follow dlib installation guides; or use prebuilt wheels for your platform.

- Issue: No faces detected
  - Solution: verify camera feed, adjust detection model and parameters, try a different detector.

- Issue: False positives / misrecognition
  - Solution: raise recognition confidence threshold, increase training samples, retrain classifier.

---

## Contributing
Contributions are welcome! Typical contributions:
- Bug fixes, improvements to detection/recognition pipeline
- Support for different detectors or embedding models
- Better UI or reporting for attendance logs
- Tests, documentation, and sample datasets

To contribute:
1. Fork the repository
2. Create a feature branch
3. Open a pull request with a clear description of changes

---

## License
This project is licensed under the MIT License. See LICENSE file for details.

---

## Acknowledgements & References
- face_recognition (ageitgey)
- dlib library
- OpenCV
- Papers and models for face embeddings (FaceNet, ArcFace, etc.)

---
